//////////////////////////////////////////
///////// 1 Area of interest //////////////
/////////////////////////////////////////


var g1 = ee.Geometry.Polygon(
    [[[11.277005891864533,63.38338420926681],
      [11.277005891864533,63.5263822705968],
      [10.818326692645783,63.5263822705968],
      [10.818326692645783,63.38338420926681]]]);
      
Map.addLayer(g1,
             {'color': 'black'},
             'Geometry [black]: polygon', false);
Map.centerObject(g1);

///////////////////////////////////////////////
//// 2 making an rgb image of study area ///
//////////////////////////////////////////////

  var visrgb = {
  bands:['B4','B3','B2'],
  min: -300,
  max: 1500,
  gamma: 1,
};
var optic = ee.ImageCollection("COPERNICUS/S2_SR");
var test = optic
  .filterBounds(g1).select(['B2','B3','B4']);
//  .filter(ee.Filter.lte('CLOUDY_PIXEL_PERCENTAGE',10)); //FILTER CLOUD COVER
 

var test_before = test.filter(ee.Filter.lte('CLOUDY_PIXEL_PERCENTAGE',10)).filter(ee.Filter.date('2021-08-01', '2021-11-01')) //FILTER DATE
  .mean()
  .clip(g1);
  // adding rgb image for background:
Map.addLayer(test_before, visrgb,'rgb before', false);

var test_after = test.filter(ee.Filter.date('2022-01-12', '2022-01-17')).median(); //FILTER DATE
  print(test_after)
Map.addLayer(test_after.clip(g1), visrgb, 'during flood rgb', false);


/////////////////////////////////////////////////////////
//    3_S1 imagery and_ S1 automatic flood detection   //
/////////////////////////////////////////////////////////

//Create a before and after image of the flooded areas in Stjørdalen

var collection = ee.ImageCollection('COPERNICUS/S1_GRD')
        .filter(ee.Filter.listContains('transmitterReceiverPolarisation', 'VH'))
        .filter(ee.Filter.listContains('transmitterReceiverPolarisation', 'VV'))
        .filter(ee.Filter.eq('instrumentMode', 'IW'))
        .filter(ee.Filter.or(ee.Filter.eq('orbitProperties_pass', 'ASCENDING'),
        ee.Filter.eq('orbitProperties_pass', 'ASCENDING')))
        .filter(ee.Filter.or(ee.Filter.eq('relativeOrbitNumber_start', 73),ee.Filter.eq('relativeOrbitNumber_stop',73)));
        
       /// due to snowcover in late november, reference images was taken earlier than the three months prior to the flood
var before = collection.filter(ee.Filter.date('2021-08-01', '2021-11-01')).filterBounds(g1);
//var before = collection.filter(ee.Filter.date('2021-11-01', '2022-01-01')).filterBounds(g1);
var after = collection.filter(ee.Filter.date('2022-01-12', '2022-01-17')).filterBounds(g1);
print(before)
print(after)

// figure out date for aquired S1 after image
// var dates_S1 = after.aggregate_array("system:time_start");

var date_S1after = after.map(function(image) {
      return ee.Feature(null, {'date': image.date().format('YYYY-MM-dd')})
    })
    .distinct('date')
    .aggregate_array('date');
    
print(date_S1after,'Dates S1 after');

var date_S1before = before.map(function(image) {
      return ee.Feature(null, {'date': image.date().format('YYYY-MM-dd')})
    })
    .distinct('date')
    .aggregate_array('date');
    
print(date_S1before,'Dates S1 before');

// figure out relative orbit number start for aquired S1 after image
var OrbitStart_S1 = after.aggregate_array("relativeOrbitNumber_start");
print(OrbitStart_S1,'S1_after relative orbit number start');

// figure out relative orbit number stop for aquired S1 after image
var OrbitStop_S1 = after.aggregate_array("relativeOrbitNumber_stop");
print(OrbitStop_S1,'S1_after relative orbit number stop');

//Select VH and VV for the "before flood" and "after flood" images
var before_VH = before.select('VH').mean().clip(g1);
var after_VH = after.select('VH').mean().clip(g1);

var before_VV = before.select('VV').mean().clip(g1);
var after_VV = after.select('VV').mean().clip(g1);




// We try now to fix the salt and pepper noise with a 
//function that shows salt and pepper as it was before and with a smoother after image
var before_filtered_VH = ee.Image(toDB(RefinedLee(toNatural(before_VH))))
var after_filtered_VH = ee.Image(toDB(RefinedLee(toNatural(after_VH))))

var before_filtered_VV = ee.Image(toDB(RefinedLee(toNatural(before_VV))))
var after_filtered_VV = ee.Image(toDB(RefinedLee(toNatural(after_VV))))

// Create thresholds for "flooded" areas
var flood_VH = before_filtered_VH.gt(-20).and(after_filtered_VH.lt(-20));
var flood_mask_VH = flood_VH.updateMask(flood_VH.eq(1));

var flood_VV = before_filtered_VV.gt(-12).and(after_filtered_VV.lt(-12));
var flood_mask_VV = flood_VV.updateMask(flood_VV.eq(1));


//showing filtered VH and VV images before and after flood
Map.addLayer(before_filtered_VH,{min: -25,max: 0}, 'before_filtered VH')
Map.addLayer(after_filtered_VH,{min: -25,max: 0}, 'after_filtered VH')

Map.addLayer(before_filtered_VV,{min: -25,max: 0}, 'before_filtered VV')
Map.addLayer(after_filtered_VV,{min: -25,max: 0}, 'after_filtered VV')


////////////////////////////////////////////
// 4_Speckle Filtering Function by Guido Lemoine//
///////////////////////////////////////////
//Applying a Refined Lee Speckle filter as coded provided by Guido Lemoine:
//https://github.com/senbox-org/s1tbx/blob/master/s1tbx-op-sar-processing/src/main/java/org/esa/s1tbx/sar/gpf/filtering/SpeckleFilters/RefinedLee.java


// Function to convert from d
function toNatural(img) {
  return ee.Image(10.0).pow(img.select(0).divide(10.0));
}

//Function to convert to dB
function toDB(img) {
  return ee.Image(img).log10().multiply(10.0);
}

function RefinedLee(img) {
  // img must be in natural units, i.e. not in dB!
  // Set up 3x3 kernels 
  var weights3 = ee.List.repeat(ee.List.repeat(1,3),3);
  var kernel3 = ee.Kernel.fixed(3,3, weights3, 1, 1, false);

  var mean3 = img.reduceNeighborhood(ee.Reducer.mean(), kernel3);
  var variance3 = img.reduceNeighborhood(ee.Reducer.variance(), kernel3);

  // Use a sample of the 3x3 windows inside a 7x7 windows to determine gradients and directions
  var sample_weights = ee.List([[0,0,0,0,0,0,0], [0,1,0,1,0,1,0],[0,0,0,0,0,0,0], [0,1,0,1,0,1,0], [0,0,0,0,0,0,0], [0,1,0,1,0,1,0],[0,0,0,0,0,0,0]]);

  var sample_kernel = ee.Kernel.fixed(7,7, sample_weights, 3,3, false);

  // Calculate mean and variance for the sampled windows and store as 9 bands
  var sample_mean = mean3.neighborhoodToBands(sample_kernel); 
  var sample_var = variance3.neighborhoodToBands(sample_kernel);

  // Determine the 4 gradients for the sampled windows
  var gradients = sample_mean.select(1).subtract(sample_mean.select(7)).abs();
  gradients = gradients.addBands(sample_mean.select(6).subtract(sample_mean.select(2)).abs());
  gradients = gradients.addBands(sample_mean.select(3).subtract(sample_mean.select(5)).abs());
  gradients = gradients.addBands(sample_mean.select(0).subtract(sample_mean.select(8)).abs());

  // And find the maximum gradient amongst gradient bands
  var max_gradient = gradients.reduce(ee.Reducer.max());

  // Create a mask for band pixels that are the maximum gradient
  var gradmask = gradients.eq(max_gradient);

  // duplicate gradmask bands: each gradient represents 2 directions
  gradmask = gradmask.addBands(gradmask);

  // Determine the 8 directions
  var directions = sample_mean.select(1).subtract(sample_mean.select(4)).gt(sample_mean.select(4).subtract(sample_mean.select(7))).multiply(1);
  directions = directions.addBands(sample_mean.select(6).subtract(sample_mean.select(4)).gt(sample_mean.select(4).subtract(sample_mean.select(2))).multiply(2));
  directions = directions.addBands(sample_mean.select(3).subtract(sample_mean.select(4)).gt(sample_mean.select(4).subtract(sample_mean.select(5))).multiply(3));
  directions = directions.addBands(sample_mean.select(0).subtract(sample_mean.select(4)).gt(sample_mean.select(4).subtract(sample_mean.select(8))).multiply(4));
  // The next 4 are the not() of the previous 4
  directions = directions.addBands(directions.select(0).not().multiply(5));
  directions = directions.addBands(directions.select(1).not().multiply(6));
  directions = directions.addBands(directions.select(2).not().multiply(7));
  directions = directions.addBands(directions.select(3).not().multiply(8));

  // Mask all values that are not 1-8
  directions = directions.updateMask(gradmask);

  // "collapse" the stack into a singe band image (due to masking, each pixel has just one value (1-8) in it's directional band, and is otherwise masked)
  directions = directions.reduce(ee.Reducer.sum());  

  //var pal = ['ffffff','ff0000','ffff00', '00ff00', '00ffff', '0000ff', 'ff00ff', '000000'];
  //Map.addLayer(directions.reduce(ee.Reducer.sum()), {min:1, max:8, palette: pal}, 'Directions', false);

  var sample_stats = sample_var.divide(sample_mean.multiply(sample_mean));

  // Calculate localNoiseVariance
  var sigmaV = sample_stats.toArray().arraySort().arraySlice(0,0,5).arrayReduce(ee.Reducer.mean(), [0]);

  // Set up the 7*7 kernels for directional statistics
  var rect_weights = ee.List.repeat(ee.List.repeat(0,7),3).cat(ee.List.repeat(ee.List.repeat(1,7),4));

  var diag_weights = ee.List([[1,0,0,0,0,0,0], [1,1,0,0,0,0,0], [1,1,1,0,0,0,0], 
    [1,1,1,1,0,0,0], [1,1,1,1,1,0,0], [1,1,1,1,1,1,0], [1,1,1,1,1,1,1]]);

  var rect_kernel = ee.Kernel.fixed(7,7, rect_weights, 3, 3, false);
  var diag_kernel = ee.Kernel.fixed(7,7, diag_weights, 3, 3, false);

  // Create stacks for mean and variance using the original kernels. Mask with relevant direction.
  var dir_mean = img.reduceNeighborhood(ee.Reducer.mean(), rect_kernel).updateMask(directions.eq(1));
  var dir_var = img.reduceNeighborhood(ee.Reducer.variance(), rect_kernel).updateMask(directions.eq(1));

  dir_mean = dir_mean.addBands(img.reduceNeighborhood(ee.Reducer.mean(), diag_kernel).updateMask(directions.eq(2)));
  dir_var = dir_var.addBands(img.reduceNeighborhood(ee.Reducer.variance(), diag_kernel).updateMask(directions.eq(2)));

  // and add the bands for rotated kernels
  for (var i=1; i<4; i++) {
    dir_mean = dir_mean.addBands(img.reduceNeighborhood(ee.Reducer.mean(), rect_kernel.rotate(i)).updateMask(directions.eq(2*i+1)));
    dir_var = dir_var.addBands(img.reduceNeighborhood(ee.Reducer.variance(), rect_kernel.rotate(i)).updateMask(directions.eq(2*i+1)));
    dir_mean = dir_mean.addBands(img.reduceNeighborhood(ee.Reducer.mean(), diag_kernel.rotate(i)).updateMask(directions.eq(2*i+2)));
    dir_var = dir_var.addBands(img.reduceNeighborhood(ee.Reducer.variance(), diag_kernel.rotate(i)).updateMask(directions.eq(2*i+2)));
  }

  // "collapse" the stack into a single band image (due to masking, each pixel has just one value in it's directional band, and is otherwise masked)
  dir_mean = dir_mean.reduce(ee.Reducer.sum());
  dir_var = dir_var.reduce(ee.Reducer.sum());

  // A finally generate the filtered value
  var varX = dir_var.subtract(dir_mean.multiply(dir_mean).multiply(sigmaV)).divide(sigmaV.add(1.0));

  var b = varX.divide(dir_var);

  var result = dir_mean.add(b.multiply(img.subtract(dir_mean)));
  return(result.arrayFlatten([['sum']]));
}



///////////////////////////////////////
// 5 Pixel, slope and elevation mask //
///////////////////////////////////////

var connected_pixels = 8;
var connections_VH = flood_mask_VH.connectedPixelCount(25);
var connections_VV = flood_mask_VV.connectedPixelCount(25);
var separated_areas_VH = connections_VH.lt(connected_pixels);
var separated_areas_VV = connections_VV.lt(connected_pixels);
var separated_areas_mask_VH = separated_areas_VH.not();
var separated_areas_mask_VV = separated_areas_VV.not();
Map.addLayer(separated_areas_VH.selfMask(), {min:0, max:1, palette: ['yellow']}, 'Disconnected areas VH', false);
Map.addLayer(separated_areas_VV.selfMask(), {min:0, max:1, palette: ['yellow']}, 'Disconnected areas VV', false);

var flood_mask_VH = flood_mask_VH.updateMask(separated_areas_mask_VH);
var flood_mask_VV = flood_mask_VV.updateMask(separated_areas_mask_VV);

//Here we use AW3D DSM to detect areas that have a slope dip above 5 degrees 
//and find elevation limit for study area in question
var dataset = ee.ImageCollection('JAXA/ALOS/AW3D30/V3_2')
.filterBounds(g1);
var elevation = dataset.select('DSM');
var elevation2 = dataset.select('DSM').mean().clip(g1);
var elevationVis = {
  min: 0,
  max: 1500,
  palette:['black','white']
};
Map.centerObject(g1);
Map.addLayer(elevation2, elevationVis, 'Elevation', false);

// Reproject an image mosaic using a projection from one of the image tiles,
// rather than using the default projection returned by .mosaic().
var proj = elevation.first().select(0).projection();
print(proj, 'projection DEM');
var slopeReprojected = ee.Terrain.slope(elevation.mosaic()
                             .setDefaultProjection(proj));
var highreproj = elevation.mosaic().setDefaultProjection(proj);
Map.addLayer(slopeReprojected, {min: 0, max: 45}, 'Slope', false);


//mask out areas with more than 5 percent slope and apply the elevation mask
var elevationtreshold = 30;
var slopetreshold = 5;
var steepareas = slopeReprojected.gt(slopetreshold);
var high = highreproj.gt(elevationtreshold);
var highmask = high.not();
var slopemask = steepareas.not();
var slopehigh = slopeReprojected.gt(slopetreshold).and(high);
var slopa = slopehigh.not();
Map.addLayer(high.selfMask(), {min:0, max:1, palette: ['green']}, 'High Areas', false);
Map.addLayer(steepareas.selfMask(), {min:0, max:1, palette: ['cyan']}, 'Steep Areas', false);
Map.addLayer(slopehigh.selfMask(), {min:0, max:1, palette: ['orange']}, 'SH', false);
//Updating the flood for the slope threshold
var flood_mask_VH_slope = flood_mask_VH.updateMask(slopemask);
var flood_mask_VV_slope = flood_mask_VV.updateMask(slopemask);

//Updating the flood for the elevation threshold 
var flood_mask_VH_high = flood_mask_VH.updateMask(highmask);
var flood_mask_VV_high = flood_mask_VV.updateMask(highmask);

//Updating the flood for the elevation and slope threshold 
var flood_mask_VH_sh = flood_mask_VH.updateMask(slopa);
var flood_mask_VV_sh = flood_mask_VV.updateMask(slopa);

// we add maps for:  flood mask with slope, 
//flood mask with elevation, flood mask with slope and elevation

//1. flood mask without slope and elevation
Map.addLayer(flood_mask_VH,{palette:['Red']}, 'Flood_Inudation VH');
Map.addLayer(flood_mask_VV,{palette:['Red']}, 'Flood_Inudation VV');

//2. flood mask with slope
Map.addLayer(flood_mask_VH_slope,{palette:['Red']}, 'Flood_Inudation with slope VH');
Map.addLayer(flood_mask_VV_slope,{palette:['Red']}, 'Flood_Inudation with slope VV');

//3. flood mask with elevation
Map.addLayer(flood_mask_VH_high,{palette:['Red']}, 'Flood_Inudation with elevation VH');
Map.addLayer(flood_mask_VV_high,{palette:['Red']}, 'Flood_Inudation with elevation VV');

//4. flood mask with elevation and slope included
Map.addLayer(flood_mask_VH_sh,{palette:['Red']}, 'Flood_Inudation with e and s VH');
Map.addLayer(flood_mask_VV_sh,{palette:['Red']}, 'Flood_Inudation with e and s VV');

//////////////////////////////////////////////
// 6_NDWI_Normalizes_Difference_Water_Index //
//////////////////////////////////////////////
//We try to create a NDWI, but this failed in Stjørdalen due to cloud cover

//SENTINEL2
// filter collection 
    
var optical = optic
  .filterBounds(g1);

var optical_before = optical.filter(ee.Filter.date('2021-06-06', '2021-09-01'))
  .filter(ee.Filter.lte('CLOUDY_PIXEL_PERCENTAGE',30))
  .mean()
  .clip(g1);
print(optical_before,'optical before');

var optical_1after = optical.filter(ee.Filter.date('2022-01-12', '2022-01-25')); 
  
var optical_after = optical.filter(ee.Filter.date('2022-01-19', '2022-01-25'))
  .mosaic()
  .clip(g1);

print(optical_after,'optical after');

var orbits_after = optical_1after.aggregate_array('SENSING_ORBIT_NUMBER').distinct().sort();
var directions_after = optical_1after.aggregate_array('SENSING_ORBIT_DIRECTION').distinct().sort();

print('Orbit Numbers:', orbits_after);
print('Orbit Directions:', directions_after);

//CALCULATION OF NDWI WITH SENTINEL 2: (BAND3-BAND8)/(BAND3+BAND8) = GREEN-NIR / GREEN+NIR

var green_after = optical_after.select('B3');
var nir_after = optical_after.select('B8');
var NDWI_after = green_after.subtract(nir_after).divide(green_after.add(nir_after)).rename('NDWI_after');

var green_before = optical_before.select('B3');
var nir_before = optical_before.select('B8');
var NDWI_before = green_before.subtract(nir_before).divide(green_before.add(nir_before)).rename('NDWI_before');

// Create a palette colour scheme for NDWI
var ndwiVis = {
  min: -1, max: 1, 
  palette: ['FF0000', 'FFA500', 'FFFF00', 'ADD8E6','0ba4d6','00008B']
};

Map.addLayer(NDWI_after, ndwiVis, 'NDWI after', false);
Map.addLayer(NDWI_before, ndwiVis, 'NDWI before', false);

// Figure out date for aquired NDWI after image
var dates_ndwi = optical_1after.map(function(image) {
      return ee.Feature(null, {'date': image.date().format('YYYY-MM-dd')})
    })
    .distinct('date')
    .aggregate_array('date');
    
print(dates_ndwi,'Dates S2 after');

var optical_before2 = optical.filter(ee.Filter.date('2021-06-06', '2021-09-01'))//use same date as optical before, but dont use.mean to get total number of images
 .filter(ee.Filter.lte('CLOUDY_PIXEL_PERCENTAGE',30))
  //.mean()
  .filterBounds(g1);

var dates_before_ndwi = optical_before2.map(function(image) {
      return ee.Feature(null, {'date': image.date().format('YYYY-MM-dd')})
    })
    .distinct('date')
    .aggregate_array('date');
    
print(dates_before_ndwi,'Dates S2 before');

//Making a flood treshold for ndwi
var floodNDWI = NDWI_before.lt(0.2).and(NDWI_after.gt(0));
var flood_maskNDWI = floodNDWI.updateMask(floodNDWI.eq(1));

Map.addLayer(flood_maskNDWI, {palette:['Red']}, 'NDWI flood mask', false);


///////////////////////////////////////////////
// 7 land cover data used in chapter 2 of thesis //
///////////////////////////////////////////////
var  LandCover = ee.ImageCollection("COPERNICUS/Landcover/100m/Proba-V-C3/Global");
var lc_stjor = LandCover
.filter(ee.Filter.date('2015-01-28', '2016-09-01'))
.filterBounds(g1);

var lc_stjor1 = lc_stjor.first().clip(g1);
var paletteLC = {
  bands: ['discrete_classification'],
};
Map.addLayer(lc_stjor1, paletteLC, 'Land Cover', false );


/////////////////////////////////////////
/// 8. Calculate total inundated areas ///
/////////////////////////////////////////

// code that prints total flooded area
var stats_VH = flood_mask_VH.multiply(ee.Image.pixelArea()).reduceRegion({
  reducer: ee.Reducer.sum(),
  geometry: g1,
  scale: 10,
  crs: 'EPSG:32632',
  maxPixels: 1e13,
  tileScale: 16
})

print(stats_VH);
var flood_area_VH = ee.Number(stats_VH.get('sum')).divide(1000000);
print('Flooded Area VH (KM2)', flood_area_VH)

var stats_VV = flood_mask_VV.multiply(ee.Image.pixelArea()).reduceRegion({
  reducer: ee.Reducer.sum(),
  geometry: g1,
  scale: 10,
  crs: 'EPSG:32632',
  maxPixels: 1e13,
  tileScale: 16
})

print(stats_VV);
var flood_area_VV = ee.Number(stats_VV.get('sum')).divide(1000000);
print('Flooded Area VV (KM2)', flood_area_VV)


// code that prints total area of the flooded area, including slope/elevation mask
var stats_VH_sh = flood_mask_VH_sh.multiply(ee.Image.pixelArea()).reduceRegion({
  reducer: ee.Reducer.sum(),
  geometry: g1,
  scale: 10,
  crs: 'EPSG:32632',
  maxPixels: 1e13,
  tileScale: 16
})

print(stats_VH_sh);
var flood_area_VH_sh = ee.Number(stats_VH_sh.get('sum')).divide(1000000);
print('Flooded Area VH SH (KM2)', flood_area_VH_sh)

var stats_VV_sh = flood_mask_VV_sh.multiply(ee.Image.pixelArea()).reduceRegion({
  reducer: ee.Reducer.sum(),
  geometry: g1,
  scale: 10,
  crs: 'EPSG:32632',
  maxPixels: 1e13,
  tileScale: 16
})

print(stats_VV_sh);
var flood_area_VV_sh = ee.Number(stats_VV_sh.get('sum')).divide(1000000);
print('Flooded Area SH VV (KM2)', flood_area_VV_sh)


////////////////////////////////////////////
///// 9. Intersection of S1 and S2 imagery // 
///// and calculated area of intersect //////
//////////////////////////////////////////

// find intersection between s1 VV and VH, we use the masks that include SEM
var floodIntersection3 = flood_mask_VH_sh.and(flood_mask_VV_sh);
Map.addLayer(floodIntersection3,{ palette: ['salmon']},"intersect of vh and vv");

var interesectionarea3 = floodIntersection3.multiply(ee.Image.pixelArea()).reduceRegion({
  reducer: ee.Reducer.sum(),
  geometry: g1,
  scale: 30,
  crs: 'EPSG:4326',
  tileScale: 16,
  maxPixels: 1e13
});

var flood_area_interesectionarea3 = ee.Number(interesectionarea3.get('sum')).divide(1000000); 
print('Flooded Area intersection vh and vv (KM2)', flood_area_interesectionarea3);


